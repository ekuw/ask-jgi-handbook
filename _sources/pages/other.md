
Thanks so much for getting in touch. We have a few different types of
events and activities that might be interesting to you. For example,
training, talks/seminars, and data science competitions with cash
prizes. I'd definitely recommend signing up to our mailing list if
that's of interest to you:
http://www.bristol.ac.uk/golding/join-our-mailing-list/ - we also pass
on opportunities that are available at the Alan Turing Institute. 

    Our colleagues in the JGI who are organising the JGI Showcase in
    February, you can contact them at: jgi-admin@bristol.ac.uk
	    Roman Shkunov is the president of the Bristol's student Data
        Science Society, I know he was looking for suggestions for
        speakers recently: qv18917@bristol.ac.uk 
		    The Heilbronn Institute runs a Data Science seminar series
            (technical content) : heilbronn-manager@bristol.ac.uk
			    The careers service might be interested in inviting
                speakers for the kinds of talks you have in
                mind. careers-service@bristol.ac.uk 





Survey wording:
I noticed that in some versions of your surveys you don't use the most inclusive choices for Gender (while in other versions you do appear to). I would definitely cast my vote for including a 'non-binary' and 'prefer not to say' option for the Gender question on all surveys, to make sure that no one feels they need to choose an option that doesn't apply to them. For the sexuality question as well, it would be more inclusive to have an 'other' or 'not listed' option in addition to 'prefer not to say' to cover for example asexual/pansexual/queer-identifying people.

I wasn't sure how the people filling out the form will be told about it's purpose. On one form, I noticed that the consent/explanation of how the data will be used came at the bottom of the form, which leads me to think that people might approach it with suspicion if they are distrustful of the police already. I thought you might get better engagement if you explain this at the beginning of the survey? Jo is probably better to advise on this next point, but I wasn't sure how the questionnaire will be presented to young people and whether they understand the dual purpose of the form as a chance to be listened to and a chance for you (the police) to help ensure that approaches to preventing criminal consequences (for lack of a better word) are successful for everyone. I'm not sure how this should be phrased, but I think it would be important for them to understand.

Analysis plan and survey design:
Really my main take-away from reading the materials, is that in order for this survey to be fit for purpose for qualitative and quantitative analysis, I think you really need to create your analysis plan now (before you stop being able to make changes to this form). That probably seems like it will slow things down, but I promise in my experience it really speeds things up, because you won't need to collect the data twice. This could be a useful resource for considering this: https://code.statisticsauthority.gov.uk/working-in-line-with-the-code/how-the-code-of-practice-for-statistics-can-help-support-evaluation/

The first thing to do is to narrow down a list of questions that you want to know the answer to, so you already gave some to Emily, but you mentioned a lot of further ones in the meeting, for example:

    Do you need better training?
    Is it better to send certain demographics of officers to certain locations?
    Can these visits be used to identify maintenance or cleanliness concerns?
    Are some demographics better served by the existing format than others?

My feeling is that these questions and the ones that you sent to Emily won't be easy to answer with the survey in its current form, so definitely this is an area that would be benefitical to address. 

After that, then key questions that you need to ask yourself in order to do this is:

    How will you measure each of the things you are interested in, e.g. how are you planning on measuring unconscious bias?
    What other data will be linked to this data, e.g. officer demographics, other information about the young people, how the case escalated.
    What kind of statistics are you hoping to use? You need to decide this for each question you hope to answer. How will you decide this?
    How strong a statement (statistically) do you need in order for your work to influence policy?
    Do you plan on sharing the results with other forces, e.g. (totally fabricated example) if you found that sending black officers to interact with black young people leads to less criminal escalation, (how) would you share that? If so, how will you ensure that results don't identify anyone.

Being able to answer those questions will help you to figure any more fine-toothed changes to the survey, as well as who to engage with to ensure that the analysis is trustworthy and fit-for-purpose for decision-making.

I understand that at the moment you can't answer some of these questions because you don't know who will be doing the analysis yet, and that constrains the expertise and time that you have available, but I just wanted to flag the importance of considering some of these thingsas soon as you can if you do want to get that second use out of the survey.

Free text and other options
If you hope to be able to "code" responses to the free text boxes (eg. in order to determine whether individuals are experiencing domestic violence at home, have someone read the responses and fill in a ), then you will find extracting the data that you need is going to be quite a laborious process that may need to be done by an expert. Note: I'm not experienced with qualitative analysis, but I recognise the time and effort that this kind of work takes to do well. I also think that free text boxes can be a really rich source of information and a great opportunity to listen to the young people, so I'm not necessarily suggesting removing these, but it's worth thinking about whether the questions that you want to answer requires them - and whether you will have the resource to make use of them.

An alternative option would be have the officer ask some questions verbally and then fill in a tick-box filled in by the child to check whether they felt heard in explaining those questions, and one for the officer which notes whether key things were present (e.g. mentions of domestic violence or any other key things that you would like to have noted). This might be quicker (less writing for the officer), as well as less work in anonymisation and digitisation later.

Distribution and digitisation: Would it ever be sensible in your line of work to use a digital version of the survey, which would again cut down on the work of you digitising it?

That's it for my initial thoughts! 

My expertise is in making sure that analysis is trustworthy and fair, so once you have the analysis plan in place, that might be something that I would be able to collaborate on further ðŸ™‚. I hope this is useful for now and I look forward to meeting with you again soon. 
